example data set reviews:

To download the file: we run this on the virtual machine (or bash linux)
wget https://dst-de.s3.eu-west-3.amazonaws.com/elasticsearch_fr/datasets/EmployerReviews.csv

- We will now have to transform and send this data to our cluster. 
To do this, copy the script below into a ***bulk_script.py*** file
************************************************************************************
nano bulk_script.py

#! /usr/bin/python
from elasticsearch import Elasticsearch, helpers
import csv

# Connexion to cluster
es = Elasticsearch(hosts = "http://@localhost:9200")

# Uncomment this command if you are using the secure installation with 3 nodes

*****#es = Elasticsearch(hosts = "https://elastic:datascientest@localhost:9200",ca_certs="./ca/ca.crt")*****


with open('EmployerReviews.csv', encoding='utf-8') as f:
    reader = csv.DictReader(f)
    helpers.bulk(es, reader, index='reviews')

******
The reader defines the type of our data, what the API will send in a helper. 
The bulk helper means a sequential scan of all the lines of our data.
************************************************************************************

- Then run the script in your machine like this:

#create folder
- mkdir elasticsearch

# enter the folder
- cd elasticsearch

#give the rights 
- sudo chmod +x ./bulk_script.py

#Installation  python
- pip3 install elasticsearch

#Execute script
- python3 ./bulk_script.py

***now we can open the cluster on kibana and we will see our dataset**

- GET /reviews/_mapping

************************************************************************************